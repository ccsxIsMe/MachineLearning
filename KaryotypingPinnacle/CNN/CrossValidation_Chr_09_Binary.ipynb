{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "slIdjqTJhM8B"
   },
   "source": [
    "# Facilitated Machine Learning Models for Karyotyping in the Patients with Chromosomal Abnormalities: Retrospective Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aBT9lgVVhM8D"
   },
   "source": [
    "- **Chuan Yang**, MD, PhD Student\n",
    "- Mentor: **Yanyan Zhao**, MD, PhD\n",
    "- Shengjing Hospital of China Medical University"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chr 09 vs Chr 09 Inversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xrnbxOZChM8E"
   },
   "source": [
    "# 0. Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aKjA8v4hhM8E"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sb\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow import keras\n",
    "\n",
    "from os import walk\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2KFSsnYohM8H"
   },
   "source": [
    "# 1. Samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Chormosome Label Convert by using Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromConvert = {\n",
    "               'chr_09': 0, \n",
    "               'chr_9_inversion': 1\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromConvert_reverse = {\n",
    "                0: 'chr_09',\n",
    "                1: 'chr_9_inversion'\n",
    "               }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. File Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1. Filename Assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8YcabYh2hM8I"
   },
   "outputs": [],
   "source": [
    "# pathBase = 'C:\\\\Users\\\\Chuan\\\\OneDrive\\\\Dowrun\\\\Database\\\\PhD\\\\KaryoTypes\\\\Arrangement\\\\'\n",
    "# pathBase = 'I:\\\\Chuan\\\\Documents\\\\MyData\\\\PhD\\\\Karyotype\\\\Arrangement\\\\'\n",
    "# pathBase = 'D:\\\\Users\\\\Chuan\\\\Documents\\\\Database\\\\Karyotypes\\\\Arrangement\\\\'\n",
    "# ///////////////////////////////////////////////\n",
    "# Merged Database\n",
    "pathBase = 'D:\\\\Users\\\\Chuan\\\\Documents\\\\Database\\\\Karyotypes\\\\Arrangement_Merged\\\\'\n",
    "\n",
    "#pathBase = 'I:\\\\Chuan\\\\Documents\\\\MyData\\\\PhD\\\\Karyotype\\\\Arrangement_Merged\\\\'\n",
    "\n",
    "theWhole = {}\n",
    "        \n",
    "f = []\n",
    "f_09 = []\n",
    "mypath_09 = pathBase + 'chr_09'\n",
    "for (dirpath, dirnames, filenames) in walk(mypath_09):\n",
    "    f.extend(filenames)\n",
    "for l in f:\n",
    "    f_09.append(mypath_09 + '\\\\' + l)    \n",
    "    \n",
    "# ///////// Abnormal ones //////////////\n",
    "\n",
    "f = []\n",
    "f_9_inversion = []\n",
    "mypath_9_inversion = pathBase + 'chr_9_inversion'\n",
    "for (dirpath, dirnames, filenames) in walk(mypath_9_inversion):\n",
    "    f.extend(filenames)\n",
    "for l in f:\n",
    "    f_9_inversion.append(mypath_9_inversion + '\\\\' + l)  \n",
    "    \n",
    "theWhole['chr_09'] = f_09\n",
    "theWhole['chr_9_inversion'] = f_9_inversion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6d8Ej2MShM8K",
    "outputId": "da32c938-49bb-4cec-9ded-708887ff9d05",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theWhole['chr_9_inversion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(theWhole['chr_09'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(theWhole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(theWhole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['chr_09', 'chr_9_inversion'])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theWhole.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's say split every class into 7 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kfold = KFold(7, True, 1)！！！\n",
    "kfold = KFold(n_splits=7, shuffle=True, random_state=1)\n",
    "# 分成7个子集，每次6个子集用于训练，1个子集用于测试\n",
    "# 每种分法进行一次训练和测试的迭代，总共8次迭代。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Assignment of filename which has been splitted randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chromosome/Abnormality:  chr_09\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot have number of splits n_splits=7 greater than the number of samples: n_samples=0.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[115], line 24\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# 依染色体或异常核型的类型进行split，因为每个类别的样本量不均衡，以每个类别进行split\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# 赋值一个generator对象，以下对generator进行迭代。\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChromosome/Abnormality: \u001b[39m\u001b[38;5;124m'\u001b[39m, chrNo)\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m generator_kFold:    \n\u001b[0;32m     25\u001b[0m     \n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m# 循环产生train和test集\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSplit Method No. \u001b[39m\u001b[38;5;124m'\u001b[39m, split_method_number)\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain: \u001b[39m\u001b[38;5;124m'\u001b[39m, train, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest: \u001b[39m\u001b[38;5;124m'\u001b[39m, test, \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mG:\\Anaconda3\\envs\\Karyotyping_Pinnacle\\lib\\site-packages\\sklearn\\model_selection\\_split.py:370\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    368\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(X)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m>\u001b[39m n_samples:\n\u001b[1;32m--> 370\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    371\u001b[0m         (\n\u001b[0;32m    372\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot have number of splits n_splits=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m greater\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    373\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m than the number of samples: n_samples=\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    374\u001b[0m         )\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits, n_samples)\n\u001b[0;32m    375\u001b[0m     )\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msplit(X, y, groups):\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m train, test\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot have number of splits n_splits=7 greater than the number of samples: n_samples=0."
     ]
    }
   ],
   "source": [
    "X_train_name = {}\n",
    "X_test_name = {}\n",
    "\n",
    "# 赋值两个接收文件路径的dictionary，其第一个key值为染色体或异常核型的名称，第二个为交叉验证（迭代）的序号\n",
    "\n",
    "for chrNo in theWhole.keys():\n",
    "\n",
    "    X_train_name[chrNo] = {}\n",
    "    X_test_name[chrNo] = {}\n",
    "    \n",
    "    # chrNo为染色体号或异常核型号，在此内部再定义迭代次数\n",
    "\n",
    "    split_method_number = 0\n",
    "    \n",
    "    # 赋值每次split分法的序号值\n",
    "\n",
    "    generator_kFold = kfold.split(theWhole[chrNo])\n",
    "    \n",
    "    # 依染色体或异常核型的类型进行split，因为每个类别的样本量不均衡，以每个类别进行split\n",
    "    # 赋值一个generator对象，以下对generator进行迭代。\n",
    "    \n",
    "    print('Chromosome/Abnormality: ', chrNo)\n",
    "\n",
    "    for train, test in generator_kFold:    \n",
    "        \n",
    "        # 循环产生train和test集\n",
    "\n",
    "        print('Split Method No. ', split_method_number)\n",
    "\n",
    "        print('Train: ', train, 'Test: ', test, '\\n')\n",
    "\n",
    "        # train和test的值是7个split分法的每个分法的list\n",
    "\n",
    "        X_train_name[chrNo][split_method_number] = []\n",
    "        X_test_name[chrNo][split_method_number] = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for split_method_train in train:\n",
    "            \n",
    "            # train 为训练集list中的序号值\n",
    "\n",
    "            # split_method_train的值是每个split方法，其值为图像序号\n",
    "            \n",
    "            X_train_name[chrNo][split_method_number].append(theWhole[chrNo][split_method_train])\n",
    "            \n",
    "            # 将训练集那个序号的图像的文件path和文件名赋值给X_train_name这个二维dictionary\n",
    "\n",
    "\n",
    "        for split_method_test in test:\n",
    "\n",
    "            # split_method_test的值是每个split方法，其值为图像序号\n",
    "            \n",
    "            X_test_name[chrNo][split_method_number].append(theWhole[chrNo][split_method_test])\n",
    "            \n",
    "            # 同样将测试集的路径和文件名赋值给X_test_name\n",
    "\n",
    "        split_method_number = split_method_number + 1\n",
    "        \n",
    "        # Split分法序号自加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train_name['chr_09'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train_name['chr_09'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_test_name['chr_09'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_name['chr_09'][1] # 表示第一轮split的方法的1号染色体的训练样本的文件名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_name['chr_09'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Filenames of Train and Test to a File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_X_train_name = open('data_X_train_name.json', 'w')\n",
    "json.dump(X_train_name, file_X_train_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_X_test_name = open('data_X_test_name.json', 'w')\n",
    "json.dump(X_test_name, file_X_test_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_theWhole = open('data_theWhole.json', 'w')\n",
    "json.dump(theWhole, file_theWhole)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the File to Acquire the Filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('data_X_train_name.json') as json_file:\n",
    "    X_train_name = json.load(json_file)\n",
    "X_train_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_X_test_name.json') as json_file:\n",
    "    X_test_name = json.load(json_file)\n",
    "X_test_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_theWhole.json') as json_file:\n",
    "    theWhole = json.load(json_file)\n",
    "theWhole"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "colab": {
   "name": "KaryoChimneyRock_FullyConnectedNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (Karyotyping_Pinnacle)",
   "language": "python",
   "name": "karyotyping_pinnacle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
